{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a pandas dataframe to geojson for web-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd, json as json, urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download data from the city of Berkeley's API. You can use Socrata's $limit parameter to specify how many rows to grab (otherwise the default is 1,000 rows of data): https://dev.socrata.com/docs/paging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API endpoint for city of Berkeley's 311 calls\n",
    "endpoint_url = 'https://data.cityofberkeley.info/resource/k489-uv4i.json?$limit=5000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open a connection to the URL\n",
    "connection = urllib.urlopen(endpoint_url)\n",
    "\n",
    "# download the results\n",
    "results = connection.read()\n",
    "\n",
    "# parse the string into a Python data structure\n",
    "data = json.loads(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, turn the json data into a dataframe and clean it up a bit: drop unnecessary columns and any rows that lack lat-long data. We want to make our json file as small as possible (prefer under 5 mb) so that it can be loaded over the Internet to anyone viewing your map, without taking forever to download a huge file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5000 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[u'apn', u'city', u'indbdate', u'issue_description', u'issue_type', u'latitude', u'location', u'longitude', u'neighborhood_district', u'object_type', u'secondary_issue_type', u'state', u'street_address', u'ticket_closed_date_time', u'ticket_created_date_time', u'ticket_id', u'ticket_status']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the json data into a dataframe and see how many rows and what columns we have\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print 'We have {} rows'.format(len(df))\n",
    "str(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert lat-long to floats and change address from ALL CAPS to regular capitalization\n",
    "df['latitude'] = df['latitude'].astype(float)\n",
    "df['longitude'] = df['longitude'].astype(float)\n",
    "df['street_address'] = df['street_address'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we don't need all those columns - only keep useful ones\n",
    "cols = ['issue_description', 'issue_type', 'latitude', 'longitude', 'street_address', 'ticket_status']\n",
    "df_subset = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2407 geotagged rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_description</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>street_address</th>\n",
       "      <th>ticket_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>Commercial Cart Size Increase</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.875968</td>\n",
       "      <td>-122.266220</td>\n",
       "      <td>1749 Oxford St</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>Commercial Site Inspection</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.871191</td>\n",
       "      <td>-122.277804</td>\n",
       "      <td>1699 University Ave</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>Residential Service Stop</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.856566</td>\n",
       "      <td>-122.254714</td>\n",
       "      <td>2616 Ashby Ave</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Commercial Missed Pickup</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.877222</td>\n",
       "      <td>-122.269296</td>\n",
       "      <td>1654 Shattuck Ave</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Residential Lost or Stolen Cart</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.869483</td>\n",
       "      <td>-122.280151</td>\n",
       "      <td>1534 Addison St</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    issue_description            issue_type   latitude  \\\n",
       "4988    Commercial Cart Size Increase  Refuse and Recycling  37.875968   \n",
       "4990       Commercial Site Inspection  Refuse and Recycling  37.871191   \n",
       "4992         Residential Service Stop  Refuse and Recycling  37.856566   \n",
       "4995         Commercial Missed Pickup  Refuse and Recycling  37.877222   \n",
       "4996  Residential Lost or Stolen Cart  Refuse and Recycling  37.869483   \n",
       "\n",
       "       longitude       street_address ticket_status  \n",
       "4988 -122.266220       1749 Oxford St        Closed  \n",
       "4990 -122.277804  1699 University Ave        Closed  \n",
       "4992 -122.254714       2616 Ashby Ave        Closed  \n",
       "4995 -122.269296    1654 Shattuck Ave        Closed  \n",
       "4996 -122.280151      1534 Addison St        Closed  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any rows that lack lat/long data\n",
    "df_geo = df_subset.dropna(subset=['latitude', 'longitude'], axis=0, inplace=False)\n",
    "\n",
    "print 'We have {} geotagged rows'.format(len(df_geo))\n",
    "df_geo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Refuse and Recycling                            1760\n",
       "Streets, Utilities, and Transportation           239\n",
       "General Questions/information                    236\n",
       "Parks, Trees and Vegetation                       70\n",
       "Environmental Services and Programs               31\n",
       "Business License                                  28\n",
       "Facilities, Electrical & Property Management      17\n",
       "Traffic and Transportation                        15\n",
       "Graffiti and Vandalism                             5\n",
       "Other Account Services and Billing                 4\n",
       "Public Records Act                                 1\n",
       "Equipment Maintenance                              1\n",
       "Name: issue_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of issue types?\n",
    "df_geo['issue_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, convert each row in the dataframe to a geojson-formatted feature and save the result as a file. The format is pretty simple and you can see it here: http://geojson.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    # create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "\n",
    "    # loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        # create a feature template to fill in\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "\n",
    "        # fill in the coordinates\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "\n",
    "        # for each column, get the value and add it as a new feature property\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        \n",
    "        # add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['street_address', 'issue_description', 'issue_type', 'ticket_status']\n",
    "geojson = df_to_geojson(df_geo, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2407 geotagged features saved to file\n"
     ]
    }
   ],
   "source": [
    "# save the geojson result to a file\n",
    "output_filename = 'dataset.js'\n",
    "with open(output_filename, 'wb') as output_file:\n",
    "    output_file.write('var dataset = ')\n",
    "    json.dump(geojson, output_file, indent=2)  \n",
    "    \n",
    "# how many features did we save to the geojson file?\n",
    "print '{} geotagged features saved to file'.format(len(geojson['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just load that dataset.js file with leaflet to map it. See berkeley-311-map.html for an example of creating the map, and see sample-blog-post.html for an example of how to display this map inside another web page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
