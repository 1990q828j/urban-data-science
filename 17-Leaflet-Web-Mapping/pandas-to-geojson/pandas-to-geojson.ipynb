{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a pandas dataframe to geojson for web-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd, requests, json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download data from the city of Berkeley's API. You can use Socrata's $limit parameter to specify how many rows to grab (otherwise the default is 1,000 rows of data): https://dev.socrata.com/docs/paging.html\n",
    "\n",
    "Example request: https://data.cityofberkeley.info/resource/k489-uv4i.json?$limit=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# API endpoint for city of Berkeley's 311 calls\n",
    "endpoint_url = 'https://data.cityofberkeley.info/resource/k489-uv4i.json?$limit=2000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch the URL and load the data\n",
    "response = requests.get(endpoint_url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, turn the json data into a dataframe and clean it up a bit: drop unnecessary columns and any rows that lack lat-long data. We want to make our json file as small as possible (prefer under 5 mb) so that it can be loaded over the Internet to anyone viewing your map, without taking forever to download a huge file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2000 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['apn', 'city', 'indbdate', 'issue_description', 'issue_type', 'latitude', 'location', 'longitude', 'neighborhood_district', 'object_type', 'secondary_issue_type', 'state', 'street_address', 'ticket_closed_date_time', 'ticket_created_date_time', 'ticket_id', 'ticket_status']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the json data into a dataframe and see how many rows and what columns we have\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print('We have {} rows'.format(len(df)))\n",
    "str(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert lat-long to floats and change address from ALL CAPS to regular capitalization\n",
    "df['latitude'] = df['latitude'].astype(float)\n",
    "df['longitude'] = df['longitude'].astype(float)\n",
    "df['street_address'] = df['street_address'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we don't need all those columns - only keep useful ones\n",
    "cols = ['issue_description', 'issue_type', 'latitude', 'longitude', 'street_address', 'ticket_status']\n",
    "df_subset = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 983 geotagged rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue_description</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>street_address</th>\n",
       "      <th>ticket_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Illegal Dumping - City Property</td>\n",
       "      <td>Streets, Utilities, and Transportation</td>\n",
       "      <td>37.874785</td>\n",
       "      <td>-122.281423</td>\n",
       "      <td>1702 Eola St</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Commercial Missed Pickup</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.875047</td>\n",
       "      <td>-122.269090</td>\n",
       "      <td>2083 Delaware St</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Residential Service Stop</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.887359</td>\n",
       "      <td>-122.261958</td>\n",
       "      <td>1169 Euclid Ave</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Miscellaneous Service Request</td>\n",
       "      <td>General Questions/information</td>\n",
       "      <td>37.869453</td>\n",
       "      <td>-122.270949</td>\n",
       "      <td>2180 Milvia St</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Residential Bulky Pickup</td>\n",
       "      <td>Refuse and Recycling</td>\n",
       "      <td>37.854516</td>\n",
       "      <td>-122.268302</td>\n",
       "      <td>2017 Emerson St Com</td>\n",
       "      <td>Closed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    issue_description                              issue_type  \\\n",
       "1991  Illegal Dumping - City Property  Streets, Utilities, and Transportation   \n",
       "1992         Commercial Missed Pickup                    Refuse and Recycling   \n",
       "1993         Residential Service Stop                    Refuse and Recycling   \n",
       "1995    Miscellaneous Service Request           General Questions/information   \n",
       "1999         Residential Bulky Pickup                    Refuse and Recycling   \n",
       "\n",
       "       latitude   longitude       street_address ticket_status  \n",
       "1991  37.874785 -122.281423         1702 Eola St        Closed  \n",
       "1992  37.875047 -122.269090     2083 Delaware St        Closed  \n",
       "1993  37.887359 -122.261958      1169 Euclid Ave        Closed  \n",
       "1995  37.869453 -122.270949       2180 Milvia St        Closed  \n",
       "1999  37.854516 -122.268302  2017 Emerson St Com        Closed  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any rows that lack lat/long data\n",
    "df_geo = df_subset.dropna(subset=['latitude', 'longitude'], axis=0, inplace=False)\n",
    "\n",
    "print('We have {} geotagged rows'.format(len(df_geo)))\n",
    "df_geo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Refuse and Recycling                            694\n",
       "Streets, Utilities, and Transportation          115\n",
       "General Questions/information                   100\n",
       "Parks, Trees and Vegetation                      27\n",
       "Business License                                 14\n",
       "Traffic and Transportation                       10\n",
       "Environmental Services and Programs              10\n",
       "Facilities, Electrical & Property Management      9\n",
       "Graffiti and Vandalism                            3\n",
       "Public Records Act                                1\n",
       "Name: issue_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of issue types?\n",
    "df_geo['issue_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, convert each row in the dataframe to a geojson-formatted feature and save the result as a file. The format is pretty simple and you can see it here: http://geojson.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def df_to_geojson(df, properties, lat='latitude', lon='longitude'):\n",
    "    # create a new python dict to contain our geojson data, using geojson format\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "\n",
    "    # loop through each row in the dataframe and convert each row to geojson format\n",
    "    for _, row in df.iterrows():\n",
    "        # create a feature template to fill in\n",
    "        feature = {'type':'Feature',\n",
    "                   'properties':{},\n",
    "                   'geometry':{'type':'Point',\n",
    "                               'coordinates':[]}}\n",
    "\n",
    "        # fill in the coordinates\n",
    "        feature['geometry']['coordinates'] = [row[lon],row[lat]]\n",
    "\n",
    "        # for each column, get the value and add it as a new feature property\n",
    "        for prop in properties:\n",
    "            feature['properties'][prop] = row[prop]\n",
    "        \n",
    "        # add this feature (aka, converted dataframe row) to the list of features inside our dict\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    return geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['street_address', 'issue_description', 'issue_type', 'ticket_status']\n",
    "geojson = df_to_geojson(df_geo, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983 geotagged features saved to file\n"
     ]
    }
   ],
   "source": [
    "# save the geojson result to a file\n",
    "output_filename = 'dataset.js'\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    output_file.write('var dataset = {};'.format(json.dumps(geojson)))\n",
    "    \n",
    "# how many features did we save to the geojson file?\n",
    "print('{} geotagged features saved to file'.format(len(geojson['features'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just load that dataset.js file with leaflet to map it. See [berkeley-311-map.html](berkeley-311-map.html) for an example of creating the map, and see [sample-blog-post.html](sample-blog-post.html) for an example of how to display this map inside another web page."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
